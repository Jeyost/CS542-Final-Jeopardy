{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON</th>\n",
       "      <th>CLUE VALUE</th>\n",
       "      <th>CLUE CATEGORY</th>\n",
       "      <th>QUESTION</th>\n",
       "      <th>OUR MODEL_ANSWER</th>\n",
       "      <th>REAL ANSWER</th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>CONTEXT USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>200</td>\n",
       "      <td>REJECTED GREETING CARDS</td>\n",
       "      <td>\\\"Have fun in\" this country! \"But remember the...</td>\n",
       "      <td>against the advice of the U.S. Department of S...</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>False</td>\n",
       "      <td>Global Relief Foundation . In November 2001, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>400</td>\n",
       "      <td>REJECTED GREETING CARDS</td>\n",
       "      <td>\\\"It's OK, applicant! You didn't want to go to...</td>\n",
       "      <td>University of Houston</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>False</td>\n",
       "      <td>Lauro Cruz . Born in Beaumont to Manuel Cruz a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>600</td>\n",
       "      <td>REJECTED GREETING CARDS</td>\n",
       "      <td>\\\"Tummyache? Next time, take a close look at\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clams</td>\n",
       "      <td>False</td>\n",
       "      <td>No Context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>800</td>\n",
       "      <td>REJECTED GREETING CARDS</td>\n",
       "      <td>\\\"Nice surgery! You finally vented\" this soft,...</td>\n",
       "      <td>The spleen</td>\n",
       "      <td>spleen</td>\n",
       "      <td>True</td>\n",
       "      <td>Splenic injury . The spleen is an organ in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1000</td>\n",
       "      <td>REJECTED GREETING CARDS</td>\n",
       "      <td>\\\"Sorry you two had\" these 14-letter \"differen...</td>\n",
       "      <td>\"irreconcilable differences\",</td>\n",
       "      <td>irreconcilable</td>\n",
       "      <td>True</td>\n",
       "      <td>Tony Parker . On 17 November 2010, Longoria fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16310</th>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>COUNTRIES BY COLLEGE</td>\n",
       "      <td>The University of Sunderland, the University o...</td>\n",
       "      <td>University of Northumbria at Newcastle.</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>Stephen Newton (artist) . Newton was born in G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16311</th>\n",
       "      <td>16</td>\n",
       "      <td>200</td>\n",
       "      <td>COUNTRIES BY COLLEGE</td>\n",
       "      <td>The Emile Cohl School, the University of Toulo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "      <td>No Context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16312</th>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>COUNTRIES BY COLLEGE</td>\n",
       "      <td>Chiba University, Waseda University, Fukuoka J...</td>\n",
       "      <td>Tokai University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>False</td>\n",
       "      <td>Tokai University Fukuoka Junior College . Toka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16313</th>\n",
       "      <td>16</td>\n",
       "      <td>200</td>\n",
       "      <td>HIRSCHFELD</td>\n",
       "      <td>Broadway's Diamond Lil; come up &amp; see her some...</td>\n",
       "      <td>Diamond Lil (play</td>\n",
       "      <td>Mae West</td>\n",
       "      <td>False</td>\n",
       "      <td>Diamond Lil (play) . Diamond Lil is a 1928 pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16314</th>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>HIRSCHFELD</td>\n",
       "      <td>No kidding! This funnyman often gets conducted...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Danny Kaye</td>\n",
       "      <td>False</td>\n",
       "      <td>No Context</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16315 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEASON  CLUE VALUE            CLUE CATEGORY  \\\n",
       "0          34         200  REJECTED GREETING CARDS   \n",
       "1          34         400  REJECTED GREETING CARDS   \n",
       "2          34         600  REJECTED GREETING CARDS   \n",
       "3          34         800  REJECTED GREETING CARDS   \n",
       "4          34        1000  REJECTED GREETING CARDS   \n",
       "...       ...         ...                      ...   \n",
       "16310      16         100     COUNTRIES BY COLLEGE   \n",
       "16311      16         200     COUNTRIES BY COLLEGE   \n",
       "16312      16         300     COUNTRIES BY COLLEGE   \n",
       "16313      16         200               HIRSCHFELD   \n",
       "16314      16         300               HIRSCHFELD   \n",
       "\n",
       "                                                QUESTION  \\\n",
       "0      \\\"Have fun in\" this country! \"But remember the...   \n",
       "1      \\\"It's OK, applicant! You didn't want to go to...   \n",
       "2      \\\"Tummyache? Next time, take a close look at\" ...   \n",
       "3      \\\"Nice surgery! You finally vented\" this soft,...   \n",
       "4      \\\"Sorry you two had\" these 14-letter \"differen...   \n",
       "...                                                  ...   \n",
       "16310  The University of Sunderland, the University o...   \n",
       "16311  The Emile Cohl School, the University of Toulo...   \n",
       "16312  Chiba University, Waseda University, Fukuoka J...   \n",
       "16313  Broadway's Diamond Lil; come up & see her some...   \n",
       "16314  No kidding! This funnyman often gets conducted...   \n",
       "\n",
       "                                        OUR MODEL_ANSWER     REAL ANSWER  \\\n",
       "0      against the advice of the U.S. Department of S...     Afghanistan   \n",
       "1                                  University of Houston        Stanford   \n",
       "2                                                    NaN           clams   \n",
       "3                                             The spleen          spleen   \n",
       "4                          \"irreconcilable differences\",  irreconcilable   \n",
       "...                                                  ...             ...   \n",
       "16310            University of Northumbria at Newcastle.         England   \n",
       "16311                                                NaN          France   \n",
       "16312                                   Tokai University           Japan   \n",
       "16313                                  Diamond Lil (play        Mae West   \n",
       "16314                                                NaN      Danny Kaye   \n",
       "\n",
       "       CORRECT                                       CONTEXT USED  \n",
       "0        False  Global Relief Foundation . In November 2001, d...  \n",
       "1        False  Lauro Cruz . Born in Beaumont to Manuel Cruz a...  \n",
       "2        False                                         No Context  \n",
       "3         True  Splenic injury . The spleen is an organ in the...  \n",
       "4         True  Tony Parker . On 17 November 2010, Longoria fi...  \n",
       "...        ...                                                ...  \n",
       "16310    False  Stephen Newton (artist) . Newton was born in G...  \n",
       "16311    False                                         No Context  \n",
       "16312    False  Tokai University Fukuoka Junior College . Toka...  \n",
       "16313    False  Diamond Lil (play) . Diamond Lil is a 1928 pla...  \n",
       "16314    False                                         No Context  \n",
       "\n",
       "[16315 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('no_training_all_question_answers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season # --> # of questions in that season\n",
      "34    13362\n",
      "16     2953\n",
      "Name: SEASON, dtype: int64\n",
      "\n",
      "category name --> # of questions in that category\n",
      "AMERICAN HISTORY          36\n",
      "WORLD HISTORY             30\n",
      "BEFORE & AFTER            25\n",
      "BOOKS & AUTHORS           25\n",
      "ISLANDS                   25\n",
      "                          ..\n",
      "CURRENT POLITICIANS        1\n",
      "FIRST LADY FACTS           1\n",
      "AMERICAN BUSINESS          1\n",
      "U.S. POLITICAL HISTORY     1\n",
      "ROMAN HISTORY              1\n",
      "Name: CLUE CATEGORY, Length: 3338, dtype: int64\n",
      "\n",
      "percent answered incorrectly and correctly\n",
      "False    0.822924\n",
      "True     0.177076\n",
      "Name: CORRECT, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# General stats\n",
    "\n",
    "# s34 aired September 11, 2017\n",
    "# s16 aired September 6, 1999\n",
    "seasons = df['SEASON'].value_counts()\n",
    "print(f'season # --> # of questions in that season\\n{seasons}\\n')\n",
    "\n",
    "categories = df['CLUE CATEGORY'].value_counts()\n",
    "print(f'category name --> # of questions in that category\\n{categories}\\n')\n",
    "\n",
    "# total questions answered correctly/incorrectly\n",
    "percent_answer_correct = df['CORRECT'].value_counts(normalize=True)\n",
    "print(f'percent answered incorrectly and correctly\\n{percent_answer_correct}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SEASON  CLUE VALUE             CLUE CATEGORY  \\\n",
      "2          34         600   REJECTED GREETING CARDS   \n",
      "9          34         400           SELF-HELP BOOKS   \n",
      "14         34         400             BACK IN BLACK   \n",
      "16         34         800             BACK IN BLACK   \n",
      "20         34         600           HIGHWAY TO HELL   \n",
      "...       ...         ...                       ...   \n",
      "16300      16        1000             \\\"B\" YOURSELF   \n",
      "16307      16         100  NEW YORK CITY TELEVISION   \n",
      "16308      16         300  NEW YORK CITY TELEVISION   \n",
      "16311      16         200      COUNTRIES BY COLLEGE   \n",
      "16314      16         300                HIRSCHFELD   \n",
      "\n",
      "                                                QUESTION OUR MODEL_ANSWER  \\\n",
      "2      \\\"Tummyache? Next time, take a close look at\" ...              NaN   \n",
      "9      In dealing with others, we need to set these l...              NaN   \n",
      "14     On the verge of going bust in 1997, it was sav...              NaN   \n",
      "16     It took more than a \"moment\", but this Rochest...              NaN   \n",
      "20     West of Akron, Route 57 takes you over this 4-...              NaN   \n",
      "...                                                  ...              ...   \n",
      "16300  Tick-Licker was the favorite rifle of this 18t...              NaN   \n",
      "16307  Ross has worked for NYC's Museum of Natural Hi...              NaN   \n",
      "16308  Louie, Latka & Elaine all worked for the Sunsh...              NaN   \n",
      "16311  The Emile Cohl School, the University of Toulo...              NaN   \n",
      "16314  No kidding! This funnyman often gets conducted...              NaN   \n",
      "\n",
      "        REAL ANSWER  CORRECT CONTEXT USED  \n",
      "2             clams    False   No Context  \n",
      "9          boundary    False   No Context  \n",
      "14            Apple    False   No Context  \n",
      "16            Kodak    False   No Context  \n",
      "20         the Styx    False   No Context  \n",
      "...             ...      ...          ...  \n",
      "16300  Daniel Boone    False   No Context  \n",
      "16307       Friends    False   No Context  \n",
      "16308          Taxi    False   No Context  \n",
      "16311        France    False   No Context  \n",
      "16314    Danny Kaye    False   No Context  \n",
      "\n",
      "[3278 rows x 8 columns]\n",
      "percentage of answers that were empty strings aka Nan: 20.091939932577382\n",
      "percentage of rows with 'no context' is: 20.091939932577382\n"
     ]
    }
   ],
   "source": [
    "# Investigate answers that were empty strings\n",
    "nan_rows = df[df['OUR MODEL_ANSWER'].isna()]\n",
    "print(nan_rows)\n",
    "\n",
    "percent_nan_rows = df['OUR MODEL_ANSWER'].isna().mean() * 100\n",
    "print(f'percentage of answers that were empty strings aka Nan: {percent_nan_rows}')\n",
    "\n",
    "# Investigate no context\n",
    "percentage_with_no_context = (df['CONTEXT USED'] == 'No Context').mean() * 100\n",
    "print(f\"percentage of rows with 'no context' is: {percentage_with_no_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of words in a question is: 14.951\n",
      "The average number of words in a question for CORRECT=True is: 15.489\n",
      "The average number of words in a question for CORRECT=False is: 14.835\n"
     ]
    }
   ],
   "source": [
    "# Investigate question length\n",
    "\n",
    "average_words = df['QUESTION'].str.split().apply(len).mean()\n",
    "average_words_true = df[df['CORRECT'] == True]['QUESTION'].str.split().apply(len).mean()\n",
    "average_words_false = df[df['CORRECT'] == False]['QUESTION'].str.split().apply(len).mean()\n",
    "\n",
    "print(f'The average number of words in a question is: {average_words:.3f}')\n",
    "print(f'The average number of words in a question for CORRECT=True is: {average_words_true:.3f}')\n",
    "print(f'The average number of words in a question for CORRECT=False is: {average_words_false:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of rows with a named entity in 'REAL ANSWER': 49.635%\n",
      "The percentage of rows with a named entity in 'REAL ANSWER' where CORRECT=True: 62.409%\n",
      "The percentage of rows with a named entity in 'REAL ANSWER' where CORRECT=False: 46.887%\n",
      "The percentage of rows without a named entity: 50.365%\n",
      "The percentage of correct rows without a named entity: 37.591%\n",
      "The percentage of incorrect rows without a named entity: 53.113%\n"
     ]
    }
   ],
   "source": [
    "# Investigate named entities\n",
    "\n",
    "# spacy built in entity types\n",
    "# PERSON - People, including fictional.\n",
    "# NORP - Nationalities or religious or political groups.\n",
    "# FAC - Buildings, airports, highways, bridges, etc.\n",
    "# ORG - Companies, agencies, institutions, etc.\n",
    "# GPE - Countries, cities, states.\n",
    "# LOC - Non-GPE locations, mountain ranges, bodies of water.\n",
    "# PRODUCT - Objects, vehicles, foods, etc. (Not services.)\n",
    "# EVENT - Named hurricanes, battles, wars, sports events, etc.\n",
    "# WORK_OF_ART - Titles of books, songs, etc.\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')      # need to run python -m spacy download en_core_web_lg\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    doc = nlp(str(text))\n",
    "    entities = [ent.text for ent in doc.ents if ent.label_ == 'PERSON' or \n",
    "                                                ent.label_ == 'NORP' or\n",
    "                                                ent.label_ == 'FAC' or\n",
    "                                                ent.label_ == 'ORG' or\n",
    "                                                ent.label_ == 'GPE' or\n",
    "                                                ent.label_ == 'LOC' or\n",
    "                                                ent.label_ == 'PRODUCT' or\n",
    "                                                ent.label_ == 'EVENT' or\n",
    "                                                ent.label_ == 'WORK_OF_ART']\n",
    "    return entities\n",
    "\n",
    "df['named_entities'] = df['REAL ANSWER'].apply(extract_named_entities)\n",
    "\n",
    "percentage_with_named_entities = (df['named_entities'].apply(lambda x: bool(x))).mean() * 100\n",
    "\n",
    "correct_rows = df[df['CORRECT'] == True]\n",
    "incorrect_rows = df[df['CORRECT'] == False]\n",
    "\n",
    "percentage_correct_with_named_entities = (correct_rows['named_entities'].apply(lambda x: bool(x))).mean() * 100\n",
    "percentage_incorrect_with_named_entities = (incorrect_rows['named_entities'].apply(lambda x: bool(x))).mean() * 100\n",
    "\n",
    "print(f\"The percentage of rows with a named entity in 'REAL ANSWER': {percentage_with_named_entities:.3f}%\")\n",
    "print(f\"The percentage of rows with a named entity in 'REAL ANSWER' where CORRECT=True: {percentage_correct_with_named_entities:.3f}%\")\n",
    "print(f\"The percentage of rows with a named entity in 'REAL ANSWER' where CORRECT=False: {percentage_incorrect_with_named_entities:.3f}%\")\n",
    "\n",
    "percentage_without_named_entities = (~df['named_entities'].astype(bool)).mean() * 100\n",
    "\n",
    "# percentage_correct_without_named_entities = (correct_rows['named_entities'].apply(lambda x: not bool(x))).mean() * 100\n",
    "# percentage_incorrect_without_named_entities = (incorrect_rows['named_entities'].apply(lambda x: not bool(x))).mean() * 100\n",
    "\n",
    "percentage_correct_without_named_entities = (~correct_rows['named_entities'].astype(bool)).mean() * 100\n",
    "percentage_incorrect_without_named_entities = (~incorrect_rows['named_entities'].astype(bool)).mean() * 100\n",
    "\n",
    "print(f\"The percentage of rows without a named entity: {percentage_without_named_entities:.3f}%\")\n",
    "print(f\"The percentage of correct rows without a named entity: {percentage_correct_without_named_entities:.3f}%\")\n",
    "print(f\"The percentage of incorrect rows without a named entity: {percentage_incorrect_without_named_entities:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of rows with a PERSON named entity in 'REAL ANSWER': 22.960%\n",
      "The percentage of rows with a PERSON named entity in 'REAL ANSWER' where CORRECT=True: 28.210%\n",
      "The percentage of rows with a PERSON named entity in 'REAL ANSWER' where CORRECT=False: 21.831%\n"
     ]
    }
   ],
   "source": [
    "def extract_people(text):\n",
    "    doc = nlp(str(text))\n",
    "    entities = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "    return entities\n",
    "\n",
    "df['PERSON'] = df['REAL ANSWER'].apply(extract_people)\n",
    "\n",
    "percentage_with_named_entities = (df['PERSON'].apply(lambda x: bool(x))).mean() * 100\n",
    "\n",
    "correct_rows = df[df['CORRECT'] == True]\n",
    "incorrect_rows = df[df['CORRECT'] == False]\n",
    "\n",
    "percentage_correct_with_named_entities = (correct_rows['PERSON'].apply(lambda x: bool(x))).mean() * 100\n",
    "percentage_incorrect_with_named_entities = (incorrect_rows['PERSON'].apply(lambda x: bool(x))).mean() * 100\n",
    "\n",
    "print(f\"The percentage of rows with a PERSON named entity in 'REAL ANSWER': {percentage_with_named_entities:.3f}%\")\n",
    "print(f\"The percentage of rows with a PERSON named entity in 'REAL ANSWER' where CORRECT=True: {percentage_correct_with_named_entities:.3f}%\")\n",
    "print(f\"The percentage of rows with a PERSON named entity in 'REAL ANSWER' where CORRECT=False: {percentage_incorrect_with_named_entities:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of rows with a GPE/LOC named entity in 'REAL ANSWER': 13.589%\n",
      "The percentage of rows with a GPE/LOC named entity in 'REAL ANSWER' where CORRECT=True: 19.522%\n",
      "The percentage of rows with a GPE/LOC named entity in 'REAL ANSWER' where CORRECT=False: 12.312%\n"
     ]
    }
   ],
   "source": [
    "def extract_places(text):\n",
    "    doc = nlp(str(text))\n",
    "    entities = [ent.text for ent in doc.ents if ent.label_ == 'GPE' or\n",
    "                                                ent.label_ == 'LOC']\n",
    "    return entities\n",
    "\n",
    "df['PLACES'] = df['REAL ANSWER'].apply(extract_places)\n",
    "\n",
    "percentage_with_named_entities = (df['PLACES'].apply(lambda x: bool(x))).mean() * 100\n",
    "\n",
    "correct_rows = df[df['CORRECT'] == True]\n",
    "incorrect_rows = df[df['CORRECT'] == False]\n",
    "\n",
    "percentage_correct_with_named_entities = (correct_rows['PLACES'].apply(lambda x: bool(x))).mean() * 100\n",
    "percentage_incorrect_with_named_entities = (incorrect_rows['PLACES'].apply(lambda x: bool(x))).mean() * 100\n",
    "\n",
    "print(f\"The percentage of rows with a GPE/LOC named entity in 'REAL ANSWER': {percentage_with_named_entities:.3f}%\")\n",
    "print(f\"The percentage of rows with a GPE/LOC named entity in 'REAL ANSWER' where CORRECT=True: {percentage_correct_with_named_entities:.3f}%\")\n",
    "print(f\"The percentage of rows with a GPE/LOC named entity in 'REAL ANSWER' where CORRECT=False: {percentage_incorrect_with_named_entities:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>daily_double_value</th>\n",
       "      <th>category</th>\n",
       "      <th>comments</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>air_date</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>River mentioned most often in the Bible</td>\n",
       "      <td>the Jordan</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scottish word for lake</td>\n",
       "      <td>loch</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American river only 33 miles shorter than the ...</td>\n",
       "      <td>the Missouri</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World's largest lake, nearly 5 times as big as...</td>\n",
       "      <td>the Caspian Sea</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>INVENTIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marconi's wonderful wireless</td>\n",
       "      <td>a radio</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468312</th>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>\\\"CC\" ME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The American Cancer Society says, \"Stay away f...</td>\n",
       "      <td>tobacco</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468313</th>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>\\\"CC\" ME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In the 5 stages of grief, it comes last</td>\n",
       "      <td>acceptance</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468314</th>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>\\\"CC\" ME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It begins as a hot dry desert wind over northe...</td>\n",
       "      <td>a sirocco</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468315</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>\\\"CC\" ME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In medicine it's the complete or partial obstr...</td>\n",
       "      <td>occlusion</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468316</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WORD ORIGINS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Theories on the origin of this, a style of jou...</td>\n",
       "      <td>gonzo</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468317 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        round  clue_value  daily_double_value        category comments  \\\n",
       "0           1         100                   0  LAKES & RIVERS      NaN   \n",
       "1           1         200                   0  LAKES & RIVERS      NaN   \n",
       "2           1         400                   0  LAKES & RIVERS      NaN   \n",
       "3           1         500                   0  LAKES & RIVERS      NaN   \n",
       "4           1         100                   0      INVENTIONS      NaN   \n",
       "...       ...         ...                 ...             ...      ...   \n",
       "468312      2         400                   0        \\\"CC\" ME      NaN   \n",
       "468313      2         800                   0        \\\"CC\" ME      NaN   \n",
       "468314      2        1200                   0        \\\"CC\" ME      NaN   \n",
       "468315      2        2000                   0        \\\"CC\" ME      NaN   \n",
       "468316      3           0                   0    WORD ORIGINS      NaN   \n",
       "\n",
       "                                                   answer         question  \\\n",
       "0                 River mentioned most often in the Bible       the Jordan   \n",
       "1                                  Scottish word for lake             loch   \n",
       "2       American river only 33 miles shorter than the ...     the Missouri   \n",
       "3       World's largest lake, nearly 5 times as big as...  the Caspian Sea   \n",
       "4                            Marconi's wonderful wireless          a radio   \n",
       "...                                                   ...              ...   \n",
       "468312  The American Cancer Society says, \"Stay away f...          tobacco   \n",
       "468313            In the 5 stages of grief, it comes last       acceptance   \n",
       "468314  It begins as a hot dry desert wind over northe...        a sirocco   \n",
       "468315  In medicine it's the complete or partial obstr...        occlusion   \n",
       "468316  Theories on the origin of this, a style of jou...            gonzo   \n",
       "\n",
       "          air_date notes  \n",
       "0       1984-09-10   NaN  \n",
       "1       1984-09-10   NaN  \n",
       "2       1984-09-10   NaN  \n",
       "3       1984-09-10   NaN  \n",
       "4       1984-09-10   NaN  \n",
       "...            ...   ...  \n",
       "468312  2023-07-28   NaN  \n",
       "468313  2023-07-28   NaN  \n",
       "468314  2023-07-28   NaN  \n",
       "468315  2023-07-28   NaN  \n",
       "468316  2023-07-28   NaN  \n",
       "\n",
       "[468317 rows x 9 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in original data from the respective seasons, not necessary but nice to have maybe\n",
    "\n",
    "df = pd.read_csv('jeopardy_clue_dataset-master/seasons/season34.tsv', sep='\\t')\n",
    "df = pd.read_csv('jeopardy_clue_dataset-master/seasons/season16.tsv', sep='\\t')\n",
    "df = pd.read_csv('jeopardy_clue_dataset-master/combined_season1-39.tsv', sep='\\t')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
